{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0b12d03-cfa1-42e1-ad25-914221a10778",
   "metadata": {
    "id": "YHK6DyunSbs4"
   },
   "source": [
    "# Vegetable Image Classification\n",
    "\n",
    "## Exercise 1: Building a Convnet from Scratch\n",
    "\n",
    "In this exercise, we will build a classifier model from scratch that is able to distinguish among 15 different types of vegetables. Similarly to our last lab, we will:\n",
    "\n",
    "1. Explore the example data\n",
    "2. Build a small convnet from scratch to solve our classification problem\n",
    "3. Evaluate training and validation accuracy\n",
    "\n",
    "Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737ecc2d-bbb2-4d3a-9fc0-b96d5798a8e6",
   "metadata": {
    "id": "UY6KJV6z6l7_"
   },
   "source": [
    "## Explore the Example Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf40c73-7f21-4779-af23-dffa6083d7d8",
   "metadata": {
    "id": "-L7r2zdl64Hg"
   },
   "source": [
    "Let's start by downloading our example data, a .zip of 21,000 JPG pictures of vegetables, and extracting it locally in `/tmp`. These data are replicated from the [Kaggle Vegetable Image Dataset](https://www.kaggle.com/datasets/misrakahmed/vegetable-image-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeb2b46-238b-44e5-8003-a6594417585d",
   "metadata": {
    "id": "RXZT2UsyIVe_"
   },
   "outputs": [],
   "source": [
    "!if ! [ -f /tmp/vegetables.zip ]; then \\\n",
    "  wget --no-check-certificate \\\n",
    "    https://cdn.c18l.org/vegetables.zip \\\n",
    "    -O /tmp/vegetables.zip; \\\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6343873-acc8-4388-b4f2-02ea32ca0a18",
   "metadata": {
    "id": "PLy3pthUS0D2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = '/tmp/vegetables.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0812ee-69f1-419f-a296-2a4ef43a86c8",
   "metadata": {
    "id": "o-qUPyfO7Qr8"
   },
   "source": [
    "The contents of the .zip are extracted to the base directory `/tmp/Vegetable Images`, which contains `train`, `test`, and `validation` subdirectories for the training and validation datasets (see the [Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/validation/check-your-intuition) for a refresher on training, validation, and test sets), which in turn each contain subdirectories for each of the image classes we'll be trying to predict. Let's define each of these directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbe8fc7-286a-4806-90d0-acfb1cb5a718",
   "metadata": {
    "id": "MLZKVtE0dSfk"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "base_dir = Path('/tmp/Vegetable Images')\n",
    "train_dir = base_dir / 'train'\n",
    "test_dir = base_dir / 'test'\n",
    "validation_dir = base_dir / 'validation'\n",
    "\n",
    "image_classes = [x.name for x in train_dir.iterdir() if x.is_dir()]\n",
    "image_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f077ccb1-9bd1-41b7-8676-5538124456e4",
   "metadata": {
    "id": "LuBYtA_Zd8_T"
   },
   "source": [
    "Now, let's see what the filenames look like for some of our vegetables in a `train` subdirectory (file naming conventions are the same in the `test` and `validation` directory):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7628b67a-39ce-4619-b5e4-4ace528147c4",
   "metadata": {
    "id": "4PIP1rkmeAYS"
   },
   "outputs": [],
   "source": [
    "train_radish_fnames = os.listdir(train_dir / image_classes[0])\n",
    "print(train_radish_fnames[:10])\n",
    "\n",
    "test_radish_fnames = os.listdir(test_dir / image_classes[0])\n",
    "print(test_radish_fnames[:10])\n",
    "\n",
    "validation_radish_fnames = os.listdir(validation_dir / image_classes[0])\n",
    "print(validation_radish_fnames[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db51d0b-5ee4-4477-8e90-d0247c7fe91f",
   "metadata": {
    "id": "HlqN5KbafhLI"
   },
   "source": [
    "Let's find out the total number of images in the `train` and `validation` directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c54f9bf-5a87-4b37-ac5e-b0b4b0983f6b",
   "metadata": {
    "id": "H4XHh2xSfgie",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('total training radish images:', len(os.listdir(train_dir / image_classes[0])))\n",
    "print('total testing radish images:', len(os.listdir(test_dir / image_classes[0])))\n",
    "print('total validation radish images:', len(os.listdir(validation_dir / image_classes[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3af147-21fe-4f63-b895-a82a8aa935ee",
   "metadata": {
    "id": "C3WZABE9eX-8"
   },
   "source": [
    "For each image class, we have 1,000 training images, 200 test images, and 200 validation images.\n",
    "\n",
    "Now let's take a look at a few pictures to get a better sense of what the dataset looks like. First, configure the matplot parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df0fa08-4731-4378-b1fb-ac697f1d01c5",
   "metadata": {
    "id": "b2_Q0-_5UAv-"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "# Index for iterating over images\n",
    "pic_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242e71ce-3e56-440f-8baf-0eb69129d774",
   "metadata": {
    "id": "xTvHzGCxXkqp"
   },
   "source": [
    "Now, display a batch of 8 radish pictures. You can rerun the cell to see a fresh batch each time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf61c1bc-98a7-4073-9c8a-0c9367b7b949",
   "metadata": {
    "id": "Wpr8GxjOU8in"
   },
   "outputs": [],
   "source": [
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "\n",
    "pic_index += 8\n",
    "next_pix = [\n",
    "    os.path.join(train_dir / image_classes[0], fname)\n",
    "    for fname in train_radish_fnames[pic_index-8:pic_index]\n",
    "]\n",
    "\n",
    "for i, img_path in enumerate(next_pix):\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis('Off')\n",
    "\n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8188aac3-301d-4081-adce-7b6f8fa97639",
   "metadata": {
    "id": "5oqBkNBJmtUv"
   },
   "source": [
    "## Building a Small Convnet from Scratch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
