{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4af29464-a957-413b-b010-3f78a56b5bc1",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "Figures taken from < https://online.stat.psu.edu/stat501/lesson/1/1.1 >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4ca58c-0a10-4832-8fca-a5837be408f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Linear Models\n",
    "\n",
    "## 2023-10-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8a90da-ceab-42f4-8c19-798110861785",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# What is linear regression?\n",
    "\n",
    "A statistical method that allows us to summarize and study relationships between two continuous (quantitative) variables:\n",
    "\n",
    "  - One variable, denoted $x$, is regarded as the **predictor**, explanatory, or independent variable.\n",
    "  - The other variable, denoted $y$, is regarded as the **label**, outcome, or dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ce9f86-2a01-48f5-acbf-fed2280e6ad3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Types of relationships\n",
    "\n",
    "![celsius / Fahrenheit graph](assets/temperature.jpeg)\n",
    "\n",
    "Although **deterministic relationships** can often be linear, there's not much point in modelling them. We know that $\\text{Fahr} = \\frac{9}{5}\\text{Cels}+32$ exactly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267cd82b-f332-4063-939d-905c3ec6124f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Statistical relationships\n",
    "\n",
    "![latitude / skin cancer incidence graph](assets/cancer.png)\n",
    "\n",
    "The label, $y$, is the mortality due to skin cancer (number of deaths per 10 million people) and the predictor, $x$, is the latitude (degrees North) at the center of each of lower 48 states in the United States ([U.S. Skin Cancer data](https://online.stat.psu.edu/onlinecourses/sites/stat501/files/data/skincancer.txt)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e25fbbe-85a5-4c70-940c-8b24e8e7ff9a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Line of best fit\n",
    "\n",
    "Given that:\n",
    "  - $y_{i}$ denotes the observed label for input $i$\n",
    "  - $x_{i}$ denotes the observed predictor for input $i$\n",
    "  - $\\hat{y}_{i}$ denotes the predicted label for input $i$\n",
    "  \n",
    "We can define the equation for a best fitting line as:\n",
    "$$\n",
    "\\hat{y}_{i} = b_{0}+b_{1}x_{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb653b81-2003-4e89-9769-2f753e6a2d05",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Observation vs prediction\n",
    "\n",
    "Because we're measuring **statistical** and not **deterministic** relationships, there will always be some error in our predictions (a **residual**). This can be quantified as\n",
    "\n",
    "$$\n",
    "e_{i} = y_{i} - \\hat{y}_{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059038a6-e55d-4939-afce-2e7a28701c13",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Least squares criterion\n",
    "\n",
    "One way to minimize the prediction error is to minimize the sum of the squared prediction errors:\n",
    "\n",
    "$$\n",
    "Q = \\sum^{n}_{i=1}(y_{i}-\\hat{y}_{i})^{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4da17b-9462-4074-a7ca-a56aa9c19755",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Applied to a linear regression, we minimize the equation for the sum of squared prediction errors:\n",
    "\n",
    "$$\n",
    "Q = \\sum^{n}_{i=1}(y_{i}-(b_{0}+b_{1}x_{i}))^{2}\n",
    "$$\n",
    "\n",
    "to get the **least squares estimates** for $b_{0}$ and $b_{1}$:\n",
    "\n",
    "$$\n",
    "b_{0} = \\bar{y}-b_{1}\\bar{x} \\\\\n",
    "b_{1} = \\frac{\\sum^{n}_{i=1}(x_{i}-\\bar{x})(y_{i}-\\bar{y})}{\\sum^{n}_{i=1}(x_{i}-\\bar{x})^{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d37667-9fd6-45f6-baf3-88f03445411a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Simple linear regression\n",
    "\n",
    "Linear regressions have four general conditions to be valid predictors:\n",
    "  - **Linear function**: The mean of the response, $E(Y_{i})$, at each value of $x_{i}$ is a linear function of $x_{i}$\n",
    "  - **Independent**: The errors, $e_{i}$, are independent\n",
    "  - **Normally distributed**: The errors, $e_{i}$, at each value of $x_{i}$ follow a Normal distribution\n",
    "  - **Equal variances**: The errors, $e_{i}$, at each value of $x_{i}$ have equal variances, denoted $\\sigma^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1605f5f-2ac1-47f4-a034-3fde4370b8ab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Residuals vs fit\n",
    "\n",
    "![residual vs fit plot](assets/residual.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f45de0-88cc-42c1-86f6-070da5ded677",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![residual patterns](assets/residual-patterns.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deda6a76-2a52-4551-b30e-5bc18d36665c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Multiple regression\n",
    "\n",
    "Multiple linear regression that relates a $y$-variable to $n-1$ $x$-variables is denoted by:\n",
    "\n",
    "$$\n",
    "y_{i} = \\beta_{0} + \\beta_{1}x_{i,1}+\\beta_{2}x_{i,2} + \\ldots + \\beta_{n}x_{i,n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc74393-01a0-4cb6-8857-5b1e743fb4b8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Matrix notation\n",
    "\n",
    "$$\n",
    "\\underbrace{\n",
    "  \\vphantom{\n",
    "    \\begin{bmatrix}\n",
    "      1 & x_1 \\\\\n",
    "      1 & x_2 \\\\\n",
    "      \\vdots & \\vdots \\\\\n",
    "      1 & x_n\n",
    "    \\end{bmatrix}\n",
    "  }\n",
    "  \\begin{bmatrix}\n",
    "    y_1 \\\\\n",
    "    y_2 \\\\\n",
    "    \\vdots \\\\\n",
    "    y_n\n",
    "  \\end{bmatrix}\n",
    "}_{\n",
    "  \\begin{gathered}\n",
    "    Y\n",
    "  \\end{gathered}\n",
    "} = \\underbrace{\n",
    "  \\begin{bmatrix}\n",
    "    1 & x_1 \\\\\n",
    "    1 & x_2 \\\\\n",
    "    \\vdots &\\vdots \\\\\n",
    "    1&x_n\n",
    "  \\end{bmatrix}\n",
    "}_{\n",
    "  \\begin{gathered}\n",
    "    =X\n",
    "  \\end{gathered}\n",
    "}\n",
    "\\underbrace{\n",
    "  \\vphantom{\n",
    "    \\begin{bmatrix}\n",
    "      1 & x_1 \\\\\n",
    "      1 & x_2 \\\\\n",
    "      \\vdots & \\vdots \\\\\n",
    "      1 & x_n\n",
    "    \\end{bmatrix}\n",
    "  }\n",
    "  \\begin{bmatrix}\n",
    "    \\beta_0 \\\\\n",
    "    \\beta_1 \\\\\n",
    "  \\end{bmatrix}\n",
    "}_{\n",
    "  \\begin{gathered}\n",
    "    \\beta\n",
    "  \\end{gathered}\n",
    "} + \\underbrace{\n",
    "  \\vphantom{\n",
    "    \\begin{bmatrix}\n",
    "      1 & x_1 \\\\\n",
    "      1 & x_2 \\\\\n",
    "      \\vdots & \\vdots \\\\\n",
    "      1&x_n\n",
    "    \\end{bmatrix}\n",
    "  }\n",
    "  \\begin{bmatrix}\n",
    "    \\epsilon_1 \\\\\n",
    "    \\epsilon_2 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\epsilon_n\n",
    "  \\end{bmatrix}\n",
    "}_{\n",
    "  \\begin{gathered}\n",
    "    + \\epsilon\n",
    "  \\end{gathered}\n",
    "}\n",
    "$$\n",
    "\n",
    "or just $Y=X\\beta+\\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c410af9-e9e3-4d07-925e-71beb4d24402",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Generalized linear models\n",
    "\n",
    "There are 3 components to any GLM:\n",
    "\n",
    "  - **Random component**: specifies the probability distribution of the response variable. E.g., the normal distribution for $Y$ in a classical regression model\n",
    "  - **Systematic component**: specifies the linear combination of explanatory variables. E.g., $\\beta_{0} + \\beta_{1}x_{1}+\\beta_{2}x_{2}$ in a linear regression\n",
    "  - **Link function**: denoted $\\eta$ or $g(\\mu)$. Specifies the link between the random and systematic components. E.g., $\\eta = g(E(Y_{i}))=E(Y_{i})$ for a classical regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee2ddd2-3d1d-413a-83aa-5ad38fdc7019",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "This class of model takes the form $y_{i} \\sim N(x_{i}^{T}\\beta, \\sigma^{2})$ where\n",
    "\n",
    "  - $x_{i}$ contains known covariates, and\n",
    "  - $\\beta$ contains the coefficients to be estimated\n",
    "\n",
    "$y_{i}$ is assumed to follow an exponential family distribution with mean $\\mu_{i}$, which is assumed to be a function of $x_{i}^{T}\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f437bba9-b4fa-4a82-bdb7-486ac54f177c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Common GLMs\n",
    "\n",
    "  - Binary logistic regression\n",
    "    - Models the odds of \"success\" for a binary response variable with a logit link function\n",
    "    - Distribution is assumed to be binomial with a single trial and success probability $E(Y) = P$\n",
    "    - $\\text{logit}(P_{i}) = \\text{ln}(\\frac{P_{i}}{1-P_{i}})$\n",
    "  - Poisson regression\n",
    "    - Models how the mean of a discrete (i.e., a count) response variable $Y$ depends on a set of explanatory variables\n",
    "    - Distribution if Poisson with mean $\\lambda$\n",
    "    - Log link function is used, $\\text{ln}(\\lambda{_i})$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
