{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNZQyiNU2d8m1ByHIoIFj79",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wetherc/data-2000/blob/main/exams/final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA-2000 Final Exam"
      ],
      "metadata": {
        "id": "J5rxJNz85UCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grading Rubric"
      ],
      "metadata": {
        "id": "5Ku5wzu65daM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This final will be worth 15% of your total grade for this course. It will be graded out of 50 points, divided into 4 sections:\n",
        "\n",
        "  - Model Building: 25 points\n",
        "    - 15 points will be awarded for the actual model building (evaluating your Python code)\n",
        "    - 10 points will be awarded for the text commentary narrating your choices and explaining your rationale\n",
        "  - Model Validation/Evaluation: 25 points\n",
        "    - 5 points will be awarded by default, but may be subtracted from if there are substantial errors in your model building that negatively impact the validity of your model\n",
        "    - 10 points will be awarded for the actual model validation and evaluation (evaluating your Python code)\n",
        "    - 10 points will be awarded for the text commentary narrating your choices and explaining your rationale\n",
        "\n",
        "> **NOTE:** You will NOT be evaluated on whether you model actually makes accurate predictions or not"
      ],
      "metadata": {
        "id": "96ZGhCW65oSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Additional Resources"
      ],
      "metadata": {
        "id": "uFkXcac_nppg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an open-resource exam. You may use any available resources as references. I will be available for any questions that you have during the exam.\n",
        "\n",
        "Remember that all work must still be your own, and that this exam is governed by the [Policy on Academic Honesty outlined in our course syllabus](https://docs.google.com/document/d/1Aoh7LvTKTEZO74eOsNhLzorkLtljkuchpg3ScNM_VEs/edit#heading=h.r0b18a8gh450)."
      ],
      "metadata": {
        "id": "YFmtWI245sAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "# Image Classification: Horse or Human\n"
      ],
      "metadata": {
        "id": "uS-7fL4G5aKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this exercise, we are going to use a dataset of images of both horses and humans, taken from [TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/horses_or_humans).\n",
        "\n",
        "Our dataset contains 1,027 training images (300x300 pixels in full color) and 256 testing images, as well as a category label for each image."
      ],
      "metadata": {
        "id": "jkXyLH585k_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "Fme1Np3d1oGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the Data\n",
        "\n",
        "First, let's download our dataset and take a look at what it contains:"
      ],
      "metadata": {
        "id": "4b6ZMSQ4orzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = tfds.load(\n",
        "    'horses_or_humans',\n",
        "    split='train',\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    batch_size=-1)\n",
        "X_test, y_test = tfds.load(\n",
        "    'horses_or_humans',\n",
        "    split='test',\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    batch_size=-1)"
      ],
      "metadata": {
        "id": "6m8jDlcsopUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "viz_data, ds_info = tfds.load(\n",
        "    'horses_or_humans',\n",
        "    split='train[:10]',\n",
        "    shuffle_files=True,\n",
        "    with_info=True)\n",
        "tfds.visualization.show_examples(viz_data, ds_info)"
      ],
      "metadata": {
        "id": "fQkJBbeGpC4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra Credit"
      ],
      "metadata": {
        "id": "RnNTXMlE0wuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For 3 points of extra credit, use TensorFlow's Keras preprocessing layers to create **synthetic training data**. To do this, you can, for example:\n",
        "  - Create new records that rotate the original images a random number of degrees;\n",
        "  - Create new records that mirror the original images left-to-right or top-to-bottom;\n",
        "  - Create new records that partially crop the original images;\n",
        "  - Create records that introduce noise to the original images;\n",
        "  - etc.\n",
        "\n",
        "  For more detail on how to do this, refer to the [Data Augmentation](https://www.tensorflow.org/tutorials/images/data_augmentation) TensorFlow tutorial, and take a look at the [Image Super-Resolution](#scrollTo=aNGRuJahuk26) section of the final below."
      ],
      "metadata": {
        "id": "YZUhSvhY0yxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building"
      ],
      "metadata": {
        "id": "q-E6GTM7pzP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a Convolutional Neural Network to classify each image as either a horse or a human.\n",
        "\n",
        "Provide a narrative explanation of your choices to accompany any code. Your narrative should be substantive and enough for someone with little to no familiarity with CNNs to be able to understand what you are doing. By way of example, this should include discussion of what the major elements of a CNN are and what they do, as well as detail about your choices in parameters such as filter size and stride (or others as necessary)."
      ],
      "metadata": {
        "id": "dAjr7Vzf52R4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m7b2dXJQ52tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "lFj3L2_aqWhQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training your model, evaluate its performance. What metric(s) did you choose to optimize on? Would you say that your model performed well or poorly? How did you evaluate its performance to arrive at that conclusion?\n",
        "\n",
        "Minimally, you should consider evaluating:\n",
        "  - Your model's accuracy on the training and testing datasets;\n",
        "  - Your model's loss over time as it trained;\n",
        "  - A confusion matrix of your model's true and false positive and negative predictions; and\n",
        "  - Holistically whether your model performs \"well\" enough for the classification task, and why or why not"
      ],
      "metadata": {
        "id": "kWkO-FWn56iS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h7sPLU4Kqr26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "<a id=\"scrollTo=aNGRuJahuk26\"></a>\n",
        "\n",
        "# Image Super-Resolution"
      ],
      "metadata": {
        "id": "aNGRuJahuk26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **NOTE:** This section of the final is **optional**. If you choose to complete it, it will contribute to both the \"Model Building\" and \"Model Evaluation\" portions of the grading rubric in addition to the image classifier you have already built. This will mean that grading is more lenient; however, you will have to do additional work. There is no penalty for choosing to not complete this section.\n",
        "\n",
        "For this task, you will build an autoencoder that takes an image and creates a super-resolution version of that image. I.e., it _upscales_ the image to fill in more detail than was originally present.\n",
        "\n",
        "To build this model, we will use the same dataset as in the previous example; however, with a small twist. Your training data will be images of horses and humans that have been downsampled to 150x150 pixels, and your model output will be the **exact same** images, but at the original 300x300 pixel resolution. To help get started, I have prepared a training and testing dataset of these images for you:"
      ],
      "metadata": {
        "id": "qJGNwZ_D59aJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  tf.keras.layers.Resizing(150, 150),\n",
        "  tf.keras.layers.Resizing(300, 300),\n",
        "  tf.keras.layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "X_train_2 = resize_and_rescale(X_train, training=True)\n",
        "X_test_2 = resize_and_rescale(X_test, training=True)"
      ],
      "metadata": {
        "id": "k9tMF4991dxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the image on the right is the one we have downscaled and it shows an obvious loss of detail compared to the original on the left. Let's see if our supersampling autoencoder is able to clear up the image resolution!"
      ],
      "metadata": {
        "id": "8TIt4jli4I4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orig_img = next(iter(X_train))\n",
        "downscaled_img = next(iter(X_train_2))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "ax = plt.subplot(1, 2, 1)\n",
        "plt.imshow(orig_img)\n",
        "\n",
        "ax = plt.subplot(1, 2, 2)\n",
        "plt.imshow(downscaled_img)"
      ],
      "metadata": {
        "id": "nZxnf0Vx3gOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we will also create new y variables for our model to use as a ground truth against which to compare its predictions. These will just be the original 300x300 pixel images:"
      ],
      "metadata": {
        "id": "jGCbKfXE4XeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of \"horse\" or \"human\" labels,\n",
        "# our y variable will now be the original\n",
        "# 300x300 pixel images\n",
        "y_train_2 = X_train\n",
        "y_test_2 = X_test"
      ],
      "metadata": {
        "id": "sCZ0WwV3vwWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should reference our [Autoencoders Lab](https://github.com/wetherc/data-2000/blob/main/labs/11-16_autoencoders.ipynb) for guidance on how to structure your model. Importantly, remember:\n",
        "\n",
        "  - Your model's input should have a shape that matches the input's pixel size (300x300 pixels --- remember, we downscaled the images and then stretched them back to their original dimensions);\n",
        "  - Your model's output should have a shape that matches the output's pixel size (300x300 pixels);\n",
        "  - Your convolutional and deconvolutional layers should be careful to evenly divide your images so that you don't have rounding issues from fractional pixels;\n",
        "  - For your model's final layer, you should use TensorFlow's [UpSampling2D layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D) followed by one or more Convolutional2D layers"
      ],
      "metadata": {
        "id": "XwQR7hVCybqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building"
      ],
      "metadata": {
        "id": "0Gc7vJURyPFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a Convolutional Neural Network to classify each image as either a horse or a human.\n",
        "\n",
        "Provide a narrative explanation of your choices to accompany any code. Your narrative should be substantive and enough for someone with little to no familiarity with CNNs to be able to understand what you are doing. By way of example, this should include discussion of what the major elements of a CNN are and what they do, as well as detail about your choices in parameters such as filter size and stride (or others as necessary)."
      ],
      "metadata": {
        "id": "Hg9OoNJJ6I9v"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wl-jJTwnyRAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "O6Nvt5iUyRe9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training your model, evaluate its performance. What metric(s) did you choose to optimize on? Would you say that your model performed well or poorly? How did you evaluate its performance to arrive at that conclusion?\n",
        "\n",
        "Minimally, you should consider evaluating:\n",
        "  - Your model's accuracy on the training and testing datasets;\n",
        "  - Your model's loss over time as it trained;\n",
        "  - A visual comparison of your upsampled predicted images and the original 300x300 pixel images;\n",
        "  - Holistically whether your model performs \"well\" enough for the classification task, and why or why not"
      ],
      "metadata": {
        "id": "TFzaLhYM6Nwh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rS84f5fkyR1G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}